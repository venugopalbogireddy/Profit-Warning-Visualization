{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning - Optimal Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Note: import new json with new variables calculated below in order to save time:\n",
    "# importing new data with all the features calculated\n",
    "data = pd.read_json('data_new_var.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Num_syl</th>\n",
       "      <th>Num_words</th>\n",
       "      <th>Num_sent</th>\n",
       "      <th>Padding</th>\n",
       "      <th>FE_idx</th>\n",
       "      <th>DC_idx</th>\n",
       "      <th>DC_dif_words</th>\n",
       "      <th>Smog_Grade_idx</th>\n",
       "      <th>FK_Grade_idx</th>\n",
       "      <th>...</th>\n",
       "      <th>Padding_QA</th>\n",
       "      <th>FE_idx_QA</th>\n",
       "      <th>DC_idx_QA</th>\n",
       "      <th>DC_dif_words_QA</th>\n",
       "      <th>Smog_Grade_idx_QA</th>\n",
       "      <th>FK_Grade_idx_QA</th>\n",
       "      <th>CL_Grade_idx_QA</th>\n",
       "      <th>ARI_Grade_idx_QA</th>\n",
       "      <th>LW_Grade_idx_QA</th>\n",
       "      <th>GFox_Grade_idx_QA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56774.032258</td>\n",
       "      <td>14144.990323</td>\n",
       "      <td>9730.645161</td>\n",
       "      <td>548.268817</td>\n",
       "      <td>0.483978</td>\n",
       "      <td>34.039032</td>\n",
       "      <td>6.433118</td>\n",
       "      <td>1138.978495</td>\n",
       "      <td>4.877419</td>\n",
       "      <td>8.365591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508065</td>\n",
       "      <td>31.753656</td>\n",
       "      <td>6.553011</td>\n",
       "      <td>695.559140</td>\n",
       "      <td>3.618280</td>\n",
       "      <td>8.049462</td>\n",
       "      <td>9.966882</td>\n",
       "      <td>9.860215</td>\n",
       "      <td>5.967742</td>\n",
       "      <td>9.367742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21679.058099</td>\n",
       "      <td>5496.045418</td>\n",
       "      <td>3848.290430</td>\n",
       "      <td>183.467752</td>\n",
       "      <td>0.026133</td>\n",
       "      <td>6.149230</td>\n",
       "      <td>0.384029</td>\n",
       "      <td>305.182803</td>\n",
       "      <td>2.654779</td>\n",
       "      <td>1.351931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036184</td>\n",
       "      <td>13.947675</td>\n",
       "      <td>1.389671</td>\n",
       "      <td>197.664651</td>\n",
       "      <td>1.735308</td>\n",
       "      <td>1.881409</td>\n",
       "      <td>3.695740</td>\n",
       "      <td>3.504970</td>\n",
       "      <td>2.319350</td>\n",
       "      <td>3.697860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6473.000000</td>\n",
       "      <td>1649.700000</td>\n",
       "      <td>1031.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>23.780000</td>\n",
       "      <td>5.850000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>21.410000</td>\n",
       "      <td>5.890000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.230000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49789.000000</td>\n",
       "      <td>12310.200000</td>\n",
       "      <td>8449.000000</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>28.860000</td>\n",
       "      <td>6.220000</td>\n",
       "      <td>1011.000000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>27.840000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>619.000000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>9.160000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>8.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56398.000000</td>\n",
       "      <td>14196.600000</td>\n",
       "      <td>9746.000000</td>\n",
       "      <td>553.000000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>34.950000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1142.000000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>29.870000</td>\n",
       "      <td>6.380000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>9.520000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>63344.000000</td>\n",
       "      <td>15813.900000</td>\n",
       "      <td>10655.000000</td>\n",
       "      <td>633.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>37.320000</td>\n",
       "      <td>6.560000</td>\n",
       "      <td>1272.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>32.920000</td>\n",
       "      <td>6.580000</td>\n",
       "      <td>806.000000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>9.990000</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>210592.000000</td>\n",
       "      <td>53848.800000</td>\n",
       "      <td>37412.000000</td>\n",
       "      <td>1583.000000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>51.530000</td>\n",
       "      <td>8.920000</td>\n",
       "      <td>2998.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>157.450000</td>\n",
       "      <td>19.530000</td>\n",
       "      <td>1147.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>44.800000</td>\n",
       "      <td>40.800000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>42.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Size       Num_syl     Num_words     Num_sent    Padding  \\\n",
       "count      93.000000     93.000000     93.000000    93.000000  93.000000   \n",
       "mean    56774.032258  14144.990323   9730.645161   548.268817   0.483978   \n",
       "std     21679.058099   5496.045418   3848.290430   183.467752   0.026133   \n",
       "min      6473.000000   1649.700000   1031.000000    51.000000   0.420000   \n",
       "25%     49789.000000  12310.200000   8449.000000   477.000000   0.460000   \n",
       "50%     56398.000000  14196.600000   9746.000000   553.000000   0.480000   \n",
       "75%     63344.000000  15813.900000  10655.000000   633.000000   0.500000   \n",
       "max    210592.000000  53848.800000  37412.000000  1583.000000   0.550000   \n",
       "\n",
       "          FE_idx     DC_idx  DC_dif_words  Smog_Grade_idx  FK_Grade_idx  \\\n",
       "count  93.000000  93.000000     93.000000       93.000000     93.000000   \n",
       "mean   34.039032   6.433118   1138.978495        4.877419      8.365591   \n",
       "std     6.149230   0.384029    305.182803        2.654779      1.351931   \n",
       "min    23.780000   5.850000    280.000000        3.100000      5.600000   \n",
       "25%    28.860000   6.220000   1011.000000        3.100000      7.600000   \n",
       "50%    34.950000   6.400000   1142.000000        3.100000      8.400000   \n",
       "75%    37.320000   6.560000   1272.000000        8.800000      9.100000   \n",
       "max    51.530000   8.920000   2998.000000        8.800000     14.200000   \n",
       "\n",
       "             ...          Padding_QA   FE_idx_QA  DC_idx_QA  DC_dif_words_QA  \\\n",
       "count        ...           93.000000   93.000000  93.000000        93.000000   \n",
       "mean         ...            0.508065   31.753656   6.553011       695.559140   \n",
       "std          ...            0.036184   13.947675   1.389671       197.664651   \n",
       "min          ...            0.250000   21.410000   5.890000         2.000000   \n",
       "25%          ...            0.490000   27.840000   6.210000       619.000000   \n",
       "50%          ...            0.510000   29.870000   6.380000       698.000000   \n",
       "75%          ...            0.530000   32.920000   6.580000       806.000000   \n",
       "max          ...            0.560000  157.450000  19.530000      1147.000000   \n",
       "\n",
       "       Smog_Grade_idx_QA  FK_Grade_idx_QA  CL_Grade_idx_QA  ARI_Grade_idx_QA  \\\n",
       "count          93.000000        93.000000        93.000000         93.000000   \n",
       "mean            3.618280         8.049462         9.966882          9.860215   \n",
       "std             1.735308         1.881409         3.695740          3.504970   \n",
       "min             0.000000         6.000000         8.230000          7.000000   \n",
       "25%             3.100000         7.200000         9.160000          8.600000   \n",
       "50%             3.100000         7.900000         9.520000          9.400000   \n",
       "75%             3.100000         8.400000         9.990000         10.100000   \n",
       "max             8.800000        21.800000        44.800000         40.800000   \n",
       "\n",
       "       LW_Grade_idx_QA  GFox_Grade_idx_QA  \n",
       "count        93.000000          93.000000  \n",
       "mean          5.967742           9.367742  \n",
       "std           2.319350           3.697860  \n",
       "min           1.000000           7.200000  \n",
       "25%           4.500000           8.400000  \n",
       "50%           5.500000           8.800000  \n",
       "75%           7.000000           9.600000  \n",
       "max          18.000000          42.800000  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_gr: Get only readability predictors:\n",
    "data_gr= data[[ 'Size', 'Num_syl', 'Num_words', 'Num_sent', 'Padding', \n",
    "               'FE_idx', 'DC_idx', 'DC_dif_words', 'Smog_Grade_idx',\n",
    "               'FK_Grade_idx', 'CL_Grade_idx', 'ARI_Grade_idx', 'LW_Grade_idx', 'GFox_Grade_idx', 'Num_syl_MD', \n",
    "               'Size_MD','Num_words_MD', 'Num_sent_MD', 'Padding_MD', 'FE_idx_MD', 'DC_idx_MD', 'DC_dif_words_MD', \n",
    "               'Smog_Grade_idx_MD', 'FK_Grade_idx_MD', 'CL_Grade_idx_MD', 'ARI_Grade_idx_MD', 'LW_Grade_idx_MD', \n",
    "               'GFox_Grade_idx_MD', 'Num_syl_QA','Size_QA', 'Num_words_QA', 'Num_sent_QA', 'Padding_QA', 'FE_idx_QA', \n",
    "               'DC_idx_QA', 'DC_dif_words_QA', 'Smog_Grade_idx_QA', 'FK_Grade_idx_QA', 'CL_Grade_idx_QA', \n",
    "               'ARI_Grade_idx_QA', 'LW_Grade_idx_QA', 'GFox_Grade_idx_QA']]\n",
    "len(data_gr.columns) # 42 numerical predictors\n",
    "data_gr.describe() # depending what ML method use you might to scale first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py27/lib/python2.7/site-packages/pandas/core/frame.py:3790: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Polarity_QA</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Subjectivity_QA</th>\n",
       "      <th>neg_perc_abs</th>\n",
       "      <th>neg_perc_rel</th>\n",
       "      <th>pos_perc_abs</th>\n",
       "      <th>pos_perc_rel</th>\n",
       "      <th>unc_perc_abs</th>\n",
       "      <th>unc_perc_rel</th>\n",
       "      <th>...</th>\n",
       "      <th>v_neg_MD</th>\n",
       "      <th>v_neg_QA</th>\n",
       "      <th>v_neu</th>\n",
       "      <th>v_neu_MD</th>\n",
       "      <th>v_neu_QA</th>\n",
       "      <th>v_pos</th>\n",
       "      <th>v_pos_MD</th>\n",
       "      <th>v_pos_QA</th>\n",
       "      <th>w_mod_perc_abs</th>\n",
       "      <th>w_mod_perc_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.094675</td>\n",
       "      <td>-0.047669</td>\n",
       "      <td>0.068451</td>\n",
       "      <td>0.069818</td>\n",
       "      <td>0.018872</td>\n",
       "      <td>0.187972</td>\n",
       "      <td>0.028705</td>\n",
       "      <td>0.286304</td>\n",
       "      <td>0.015562</td>\n",
       "      <td>0.153723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054794</td>\n",
       "      <td>0.065587</td>\n",
       "      <td>0.879199</td>\n",
       "      <td>0.884357</td>\n",
       "      <td>0.879257</td>\n",
       "      <td>0.213371</td>\n",
       "      <td>0.153589</td>\n",
       "      <td>0.245192</td>\n",
       "      <td>0.007331</td>\n",
       "      <td>0.072351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.147835</td>\n",
       "      <td>0.202291</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.046538</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.043206</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.046664</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>0.034157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014699</td>\n",
       "      <td>0.041173</td>\n",
       "      <td>0.027835</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>0.038059</td>\n",
       "      <td>0.049806</td>\n",
       "      <td>0.021697</td>\n",
       "      <td>0.068170</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.018539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.227848</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>0.049780</td>\n",
       "      <td>0.042358</td>\n",
       "      <td>0.011325</td>\n",
       "      <td>0.110333</td>\n",
       "      <td>0.017044</td>\n",
       "      <td>0.177453</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.023455</td>\n",
       "      <td>0.778887</td>\n",
       "      <td>0.836053</td>\n",
       "      <td>0.762396</td>\n",
       "      <td>0.109614</td>\n",
       "      <td>0.108308</td>\n",
       "      <td>0.091524</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.034301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.010830</td>\n",
       "      <td>-0.159091</td>\n",
       "      <td>0.062305</td>\n",
       "      <td>0.057247</td>\n",
       "      <td>0.015445</td>\n",
       "      <td>0.152244</td>\n",
       "      <td>0.025709</td>\n",
       "      <td>0.262821</td>\n",
       "      <td>0.012478</td>\n",
       "      <td>0.127358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044750</td>\n",
       "      <td>0.046639</td>\n",
       "      <td>0.860199</td>\n",
       "      <td>0.873145</td>\n",
       "      <td>0.857936</td>\n",
       "      <td>0.178993</td>\n",
       "      <td>0.138208</td>\n",
       "      <td>0.199177</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>0.057812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.092784</td>\n",
       "      <td>-0.051163</td>\n",
       "      <td>0.066434</td>\n",
       "      <td>0.062940</td>\n",
       "      <td>0.018042</td>\n",
       "      <td>0.182830</td>\n",
       "      <td>0.028696</td>\n",
       "      <td>0.283159</td>\n",
       "      <td>0.015212</td>\n",
       "      <td>0.151852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053143</td>\n",
       "      <td>0.054647</td>\n",
       "      <td>0.880331</td>\n",
       "      <td>0.885531</td>\n",
       "      <td>0.875645</td>\n",
       "      <td>0.214071</td>\n",
       "      <td>0.153585</td>\n",
       "      <td>0.247348</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>0.071942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.211268</td>\n",
       "      <td>0.070968</td>\n",
       "      <td>0.073845</td>\n",
       "      <td>0.071634</td>\n",
       "      <td>0.021394</td>\n",
       "      <td>0.219643</td>\n",
       "      <td>0.031618</td>\n",
       "      <td>0.314935</td>\n",
       "      <td>0.018049</td>\n",
       "      <td>0.175497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>0.068679</td>\n",
       "      <td>0.898970</td>\n",
       "      <td>0.898300</td>\n",
       "      <td>0.901714</td>\n",
       "      <td>0.247414</td>\n",
       "      <td>0.166529</td>\n",
       "      <td>0.300054</td>\n",
       "      <td>0.008321</td>\n",
       "      <td>0.084071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.478927</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.101510</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.030227</td>\n",
       "      <td>0.297170</td>\n",
       "      <td>0.046953</td>\n",
       "      <td>0.429072</td>\n",
       "      <td>0.037829</td>\n",
       "      <td>0.343284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096667</td>\n",
       "      <td>0.318333</td>\n",
       "      <td>0.934839</td>\n",
       "      <td>0.917956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.317834</td>\n",
       "      <td>0.212932</td>\n",
       "      <td>0.360683</td>\n",
       "      <td>0.016802</td>\n",
       "      <td>0.129657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Polarity  Polarity_QA  Subjectivity  Subjectivity_QA  neg_perc_abs  \\\n",
       "count  93.000000    93.000000     93.000000        93.000000     93.000000   \n",
       "mean    0.094675    -0.047669      0.068451         0.069818      0.018872   \n",
       "std     0.147835     0.202291      0.009777         0.046538      0.004658   \n",
       "min    -0.227848    -0.999999      0.049780         0.042358      0.011325   \n",
       "25%    -0.010830    -0.159091      0.062305         0.057247      0.015445   \n",
       "50%     0.092784    -0.051163      0.066434         0.062940      0.018042   \n",
       "75%     0.211268     0.070968      0.073845         0.071634      0.021394   \n",
       "max     0.478927     0.454545      0.101510         0.500000      0.030227   \n",
       "\n",
       "       neg_perc_rel  pos_perc_abs  pos_perc_rel  unc_perc_abs  unc_perc_rel  \\\n",
       "count     93.000000     93.000000     93.000000     93.000000     93.000000   \n",
       "mean       0.187972      0.028705      0.286304      0.015562      0.153723   \n",
       "std        0.043206      0.005006      0.046664      0.004245      0.034157   \n",
       "min        0.110333      0.017044      0.177453      0.007700      0.088235   \n",
       "25%        0.152244      0.025709      0.262821      0.012478      0.127358   \n",
       "50%        0.182830      0.028696      0.283159      0.015212      0.151852   \n",
       "75%        0.219643      0.031618      0.314935      0.018049      0.175497   \n",
       "max        0.297170      0.046953      0.429072      0.037829      0.343284   \n",
       "\n",
       "            ...         v_neg_MD   v_neg_QA      v_neu   v_neu_MD   v_neu_QA  \\\n",
       "count       ...        93.000000  93.000000  93.000000  93.000000  93.000000   \n",
       "mean        ...         0.054794   0.065587   0.879199   0.884357   0.879257   \n",
       "std         ...         0.014699   0.041173   0.027835   0.017293   0.038059   \n",
       "min         ...         0.027500   0.023455   0.778887   0.836053   0.762396   \n",
       "25%         ...         0.044750   0.046639   0.860199   0.873145   0.857936   \n",
       "50%         ...         0.053143   0.054647   0.880331   0.885531   0.875645   \n",
       "75%         ...         0.063600   0.068679   0.898970   0.898300   0.901714   \n",
       "max         ...         0.096667   0.318333   0.934839   0.917956   1.000000   \n",
       "\n",
       "           v_pos   v_pos_MD   v_pos_QA  w_mod_perc_abs  w_mod_perc_rel  \n",
       "count  93.000000  93.000000  93.000000       93.000000       93.000000  \n",
       "mean    0.213371   0.153589   0.245192        0.007331        0.072351  \n",
       "std     0.049806   0.021697   0.068170        0.002250        0.018539  \n",
       "min     0.109614   0.108308   0.091524        0.003347        0.034301  \n",
       "25%     0.178993   0.138208   0.199177        0.005526        0.057812  \n",
       "50%     0.214071   0.153585   0.247348        0.007283        0.071942  \n",
       "75%     0.247414   0.166529   0.300054        0.008321        0.084071  \n",
       "max     0.317834   0.212932   0.360683        0.016802        0.129657  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_sent: Get only sentiment+syntax+semantic Indicators\n",
    "import numpy as np\n",
    "# Get only readability predictors:\n",
    "data_sent= data[[ 'Polarity', 'Polarity_QA', 'Subjectivity', 'Subjectivity_QA',\n",
    "                 'neg_perc_abs', 'neg_perc_rel', 'pos_perc_abs', 'pos_perc_rel','unc_perc_abs', 'unc_perc_rel',\n",
    "                 'v_comp', 'v_comp_MD', 'v_comp_QA', 'v_neg', 'v_neg_MD', 'v_neg_QA', 'v_neu', 'v_neu_MD', 'v_neu_QA',\n",
    "                 'v_pos', 'v_pos_MD', 'v_pos_QA', 'w_mod_perc_abs', 'w_mod_perc_rel'\n",
    "                ]]\n",
    "\n",
    "data_sent.fillna(np.nanmean(data_sent),inplace=True)\n",
    "len(data_sent.columns) # 24 numerical predictors\n",
    "data_sent.describe() # you need to scale first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.concat([data_gr,data_sent], axis=1) # Total Sample Readability + Sentiment dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML - Selected Models - Minimazing Misc. Error and Generalization Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models selected for ensemble right below are the ones with better balance Minimum Classification Error and Minimum Generalization Error:\n",
    "\n",
    "- **XGB Text**: uses data_gr\n",
    "- **PCA Logit Total**: uses df_t\n",
    "- **RF Total**: uses df_t\n",
    "- **PCA Logit Syn/Sem**: uses data_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGB Text**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses data_gr\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pred = data_gr\n",
    "target = data['Target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(pred, target, test_size=0.20, random_state=0) # Test is 20% data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [1000, 5000, 10000], 'learning_rate': [0.01, 0.005], 'colsample_bytree': [0.8], 'max_depth': [2, 3], 'nthread': [16]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune XGB model to find the best model:\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import sklearn.grid_search as gs\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "grid_para = [{ 'max_depth':[2,3], # max tree depth for base learners \n",
    "              'learning_rate':[0.01,0.005], # = eta\n",
    "              'n_estimators':[1000, 5000, 10000], # num of boosted trees to fit\n",
    "              'nthread':[16],\n",
    "              'colsample_bytree':[0.8]\n",
    "             }]\n",
    "\n",
    "grid_xgb = gs.GridSearchCV(xgb_model, grid_para, scoring='accuracy', cv=5)\n",
    "grid_xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'learning_rate': 0.005,\n",
       " 'max_depth': 3,\n",
       " 'n_estimators': 5000,\n",
       " 'nthread': 16}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Parameters\n",
    "grid_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score 1.0\n",
      "Training Error 0.0\n",
      "Overall Training Log-Loss Error 0.04085297686224048\n",
      "*****************************************************************\n",
      "Test Score 0.8421052631578947\n",
      "Test Error 0.1578947368421053\n",
      "Overall Test Log-Loss Error 0.5340331127916119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "print 'Training Score',grid_xgb.best_estimator_.score(x_train,y_train)\n",
    "print 'Training Error',1 - grid_xgb.best_estimator_.score(x_train,y_train)\n",
    "y_train_p = grid_xgb.best_estimator_.predict_proba(x_train)\n",
    "print 'Overall Training Log-Loss Error', metrics.log_loss(y_train,y_train_p)\n",
    "print '*'*65\n",
    "print 'Test Score',grid_xgb.best_estimator_.score(x_test,y_test)\n",
    "print 'Test Error',1 - grid_xgb.best_estimator_.score(x_test,y_test)\n",
    "y_test_p = grid_xgb.best_estimator_.predict_proba(x_test)\n",
    "print 'Overall Test Log-Loss Error', metrics.log_loss(y_test,y_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Input\n",
    "y_xgb_train_p = grid_xgb.best_estimator_.predict(x_train)\n",
    "y_xgb_train_prob = grid_xgb.best_estimator_.predict_proba(x_train)\n",
    "\n",
    "y_xgb_test_p = grid_xgb.best_estimator_.predict(x_test)\n",
    "y_xgb_test_prob = grid_xgb.best_estimator_.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA Logit Total**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "\n",
    "df_t_s = df_t / np.std(df_t,0) # scaling for PCA\n",
    "\n",
    "# Checking what number of PCs are best to wok with: \n",
    "pca.set_params(n_components = None)\n",
    "pca.fit(df_t_s)\n",
    "plt.plot(range(len(df_t_s.columns)), pca.explained_variance_ratio_)\n",
    "plt.scatter(range(len(df_t_s.columns)), pca.explained_variance_ratio_)\n",
    "plt.xlabel('ith components')\n",
    "plt.ylabel('Percentage of Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Explained Variance 95.0\n",
      "*****************************************************************\n",
      "Explained Variance per  PC:\n",
      "*****************************************************************\n",
      "[0.23130789 0.18092125 0.12761007 0.08097086 0.06902264 0.06169577\n",
      " 0.03537737 0.03041254 0.02749783 0.02269523 0.0209422  0.01597056\n",
      " 0.01401388 0.01110328 0.00944165 0.00866352]\n",
      "*****************************************************************\n",
      "PCA Eigenvectors\n",
      "*****************************************************************\n",
      "[[-0.1998068  -0.19680465 -0.20006277 ... -0.03305734  0.07196311\n",
      "   0.06304699]\n",
      " [ 0.13098076  0.13617806  0.12373762 ... -0.0410448   0.03932919\n",
      "   0.00886406]\n",
      " [ 0.10105844  0.10368048  0.11571214 ... -0.18744966  0.0599132\n",
      "   0.05938558]\n",
      " ...\n",
      " [ 0.01348954  0.01642016  0.01171516 ... -0.0182919   0.04395483\n",
      "   0.01962819]\n",
      " [ 0.01109968  0.01701681  0.01005861 ... -0.00614481 -0.1786937\n",
      "  -0.22796943]\n",
      " [-0.02400469 -0.02163471 -0.01315836 ...  0.04890901 -0.16725797\n",
      "  -0.19261005]]\n",
      "*****************************************************************\n",
      "PCs\n",
      "*****************************************************************\n",
      "[[-2.24472768  2.91689675 -2.27174302 ... -0.79644664 -0.32862393\n",
      "   0.3249574 ]\n",
      " [ 0.74077051 -2.74377317  1.84272791 ... -0.76081649 -0.31630535\n",
      "  -0.27826452]\n",
      " [-1.969855   -1.51245379  0.92070995 ... -0.79415845  0.26079228\n",
      "  -0.46029325]\n",
      " ...\n",
      " [ 0.05285996 -0.89133425 -0.98682075 ... -0.98855251  0.56853214\n",
      "  -0.06849885]\n",
      " [-1.90657914 -1.6068661  -1.00389789 ...  0.31862617  1.13441088\n",
      "   0.97416057]\n",
      " [ 0.00926262 -1.67459239 -1.10790196 ... -0.59606352  0.34197667\n",
      "   0.36980761]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.set_params(n_components = 16) # only obtain 16 PCs = p\n",
    "pca.fit(df_t_s)\n",
    "\n",
    "print 'Aggregated Explained Variance', 100*round(sum(pca.explained_variance_ratio_),2)\n",
    "print '*'*65\n",
    "print 'Explained Variance per  PC:'\n",
    "print '*'*65\n",
    "print pca.explained_variance_ratio_\n",
    "print '*'*65\n",
    "print 'PCA Eigenvectors'\n",
    "print '*'*65\n",
    "print pca.components_\n",
    "print '*'*65\n",
    "print 'PCs'\n",
    "print '*'*65\n",
    "print pca.transform(df_t_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is: 0.1486\n",
      "The test error is: 0.1579\n",
      "Training Multi Class Log_loss: 0.3429654746274785\n",
      "Test Multi Class Log_loss: 0.3586689153085521\n"
     ]
    }
   ],
   "source": [
    "import sklearn.cross_validation as cv\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "logit = lm.LogisticRegression()\n",
    "\n",
    "pred = df_t_s\n",
    "target = data['Target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = cv.train_test_split(pred, target, test_size=0.20, random_state=0)\n",
    "\n",
    "# PCA Training\n",
    "pca.set_params(n_components = 17) # only obtain 17 PCs out of 66\n",
    "pca.fit(x_train)\n",
    "x_train = pca.transform(x_train)  \n",
    "x_test = pca.transform(x_test)  \n",
    "\n",
    "# Logit \n",
    "logit.fit(x_train, y_train)\n",
    "print \"The training error is: %.4f\" %(1-logit.score(x_train, y_train))\n",
    "print \"The test error is: %.4f\" %(1-logit.score(x_test, y_test))\n",
    "y_train_p = logit.predict_proba(x_train)\n",
    "y_test_p = logit.predict_proba(x_test)\n",
    "print 'Training Multi Class Log_loss:', metrics.log_loss(y_train,y_train_p)\n",
    "print 'Test Multi Class Log_loss:', metrics.log_loss(y_test,y_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Input\n",
    "y_logit_train_p = logit.predict(x_train)\n",
    "y_logit_train_prob = logit.predict_proba(x_train)\n",
    "\n",
    "y_logit_test_p = logit.predict(x_test)\n",
    "y_logit_test_prob = logit.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** RF Total**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train/Test data:\n",
    "import sklearn.cross_validation as cv\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "pred = df_t\n",
    "target = data['Target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = cv.train_test_split(pred, target, test_size=0.20, random_state=0) # Test is 20% data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune RF model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import sklearn.grid_search as gs\n",
    "\n",
    "randomForest = RandomForestClassifier()\n",
    "np.random.seed(1)\n",
    "\n",
    "grid_para_forest = [{\"n_estimators\": [10, 50, 100], \"criterion\": [\"gini\", \"entropy\"], \\\n",
    "                    \"min_samples_leaf\": range(1, 10), \"min_samples_split\": range(2,31,2), \\\n",
    "                    'max_features':['auto','log2',10]}]\n",
    "grid_search_forest = gs.GridSearchCV(randomForest, grid_para_forest, scoring='accuracy', cv=5)\n",
    "# grid_search_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [10, 50, 100], 'min_samples_split': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30], 'criterion': ['gini', 'entropy'], 'max_features': ['auto', 'log2', 10], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## best parameter\n",
    "grid_search_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.878378378378\n",
      "Best Error: 0.121621621622\n",
      "*****************************************************************\n",
      "Overall Training Score: 1.0\n",
      "Overall Training Error 0.0\n",
      "Overall Training Log-Loss Error 0.1562798088858093\n",
      "*****************************************************************\n",
      "Overall Test Score: 0.7894736842105263\n",
      "Overall Test Error 0.21052631578947367\n",
      "Overall Test Log-Loss Error 0.41616006988807136\n"
     ]
    }
   ],
   "source": [
    "## best and overall score\n",
    "print 'Best Score:',grid_search_forest.best_score_\n",
    "print 'Best Error:',1- grid_search_forest.best_score_\n",
    "print 65*'*'\n",
    "print 'Overall Training Score:', grid_search_forest.score(x_train,y_train)  \n",
    "print 'Overall Training Error', 1-grid_search_forest.score(x_train,y_train)\n",
    "y_train_p = grid_search_forest.predict_proba(x_train)\n",
    "print 'Overall Training Log-Loss Error', metrics.log_loss(y_train,y_train_p)\n",
    "print 65*'*'\n",
    "print 'Overall Test Score:', grid_search_forest.score(x_test,y_test)  \n",
    "print 'Overall Test Error', 1-grid_search_forest.score(x_test,y_test)\n",
    "y_test_p = grid_search_forest.predict_proba(x_test)\n",
    "print 'Overall Test Log-Loss Error', metrics.log_loss(y_test,y_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=4,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Model Training:\n",
    "randomForest = RandomForestClassifier(criterion='gini',max_features= 'auto', min_samples_leaf= 1, \\\n",
    "                                               min_samples_split= 4, n_estimators= 50)\n",
    "randomForest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Training Score: 1.0\n",
      "Best Training Error: 0.0\n",
      "Overall Train Log-Loss Error 0.1621322257800922\n",
      "Best Test Score: 0.7894736842105263\n",
      "Best Test Error: 0.21052631578947367\n",
      "Overall Test Log-Loss Error 0.42029082031511383\n"
     ]
    }
   ],
   "source": [
    "print 'Best Training Score:',randomForest.score(x_train,y_train)\n",
    "print 'Best Training Error:',1- randomForest.score(x_train,y_train)\n",
    "y_train_p = randomForest.predict_proba(x_train)\n",
    "print 'Overall Train Log-Loss Error', metrics.log_loss(y_train,y_train_p)\n",
    "\n",
    "print 'Best Test Score:',randomForest.score(x_test,y_test)\n",
    "print 'Best Test Error:',1- randomForest.score(x_test,y_test)\n",
    "y_test_p = randomForest.predict_proba(x_test)\n",
    "print 'Overall Test Log-Loss Error', metrics.log_loss(y_test,y_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(74,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(y_train))\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Input\n",
    "y_rf_train_p = randomForest.predict(x_train)\n",
    "y_rf_train_prob = randomForest.predict_proba(x_train)\n",
    "\n",
    "y_rf_test_p = randomForest.predict(x_test)\n",
    "y_rf_test_prob = randomForest.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** PCA Logit Syn/Sem **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "\n",
    "data_sent_s = data_sent / np.std(data_sent,0) # scaling for PCA\n",
    "\n",
    "# Checking what number of PCs are best to wok with: \n",
    "pca.set_params(n_components = None)\n",
    "pca.fit(data_sent_s)\n",
    "plt.plot(range(len(data_sent_s.columns)), pca.explained_variance_ratio_)\n",
    "plt.scatter(range(len(data_sent_s.columns)), pca.explained_variance_ratio_)\n",
    "plt.xlabel('ith components')\n",
    "plt.ylabel('Percentage of Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Explained Variance 97.0\n",
      "*****************************************************************\n",
      "Explained Variance per  PC:\n",
      "*****************************************************************\n",
      "[0.29093718 0.18858639 0.1295608  0.07894691 0.06509019 0.05566414\n",
      " 0.04966892 0.03478698 0.02764545 0.02016397 0.01333225 0.01217238]\n",
      "*****************************************************************\n",
      "PCA Eigenvectors\n",
      "*****************************************************************\n",
      "[[-2.72890483e-01 -2.32800580e-01  1.79778425e-01  1.56133565e-01\n",
      "   2.63248547e-01  2.63840858e-01 -2.48377096e-01 -2.93735102e-01\n",
      "   4.61276439e-02  2.95441609e-02 -2.88536980e-01 -2.80918684e-01\n",
      "  -2.37584087e-01  1.41807346e-01  2.11190257e-01  1.19516380e-01\n",
      "   1.99809778e-01  1.91230542e-01  1.93070503e-01 -2.04614390e-01\n",
      "  -2.03748579e-01 -1.65148468e-01  4.06448099e-02  3.26658027e-02]\n",
      " [ 1.92094426e-01  2.05248202e-02 -7.11467703e-02  1.71308292e-01\n",
      "  -1.93759301e-01 -2.88996471e-01  1.28504787e-01  1.78593422e-02\n",
      "   3.35105931e-01  3.16845798e-01  1.56808921e-01  1.27353748e-01\n",
      "   1.06173285e-01  7.49033921e-03  5.46085228e-02  9.02057069e-02\n",
      "   2.72388097e-01  1.25855034e-01  3.07486501e-01 -2.57191372e-01\n",
      "  -5.54994907e-02 -2.46316077e-01  3.25050701e-01  3.07071388e-01]\n",
      " [-6.38375640e-03 -1.14915062e-01 -8.28359793e-02  2.17420056e-01\n",
      "  -5.28845730e-02 -7.62411000e-02  2.65451023e-02 -5.98579619e-03\n",
      "   2.72793669e-01  3.04191950e-01 -2.00310560e-01 -9.27005820e-02\n",
      "  -2.64463192e-01  2.58879374e-01  9.78513925e-02  3.47934224e-01\n",
      "  -3.05212870e-01 -1.86547759e-01 -2.36246900e-01  2.71851499e-01\n",
      "   1.99929201e-01  2.97952464e-01  1.59029064e-01  1.68234562e-01]\n",
      " [ 2.79267064e-01  2.05994962e-01  1.01550784e-01 -4.44357430e-02\n",
      "  -6.16182210e-02 -3.89233530e-02  2.48963185e-01  3.04163709e-01\n",
      "  -1.62451144e-01 -1.68290381e-01 -8.20537517e-02 -6.23772757e-02\n",
      "  -1.02121985e-01  4.51311486e-01  3.19274892e-01  3.69252235e-01\n",
      "   8.42784813e-02 -1.27731843e-01  9.07473773e-02 -1.82566965e-01\n",
      "  -2.30699861e-02 -1.58923642e-01 -2.18369935e-01 -2.26472915e-01]\n",
      " [-4.71111995e-03 -2.41968890e-01  4.33654098e-01  3.14416442e-01\n",
      "   2.74353368e-01  8.15350669e-02  2.93184387e-01  5.44919484e-02\n",
      "   2.25293717e-01  5.27618907e-02  8.71263542e-02  1.56332577e-01\n",
      "  -4.53736068e-02 -1.88324084e-01 -1.65974208e-01 -3.26608047e-02\n",
      "   1.67543215e-02 -2.86094575e-01  1.26143773e-01 -9.03079997e-02\n",
      "   3.47760780e-01 -9.17772245e-02 -8.99467598e-02 -2.97171011e-01]\n",
      " [ 1.01233768e-01 -2.15411911e-01 -2.64550576e-01  4.39836664e-01\n",
      "  -2.32906666e-01 -3.27624303e-02 -6.05729513e-02  2.19858052e-01\n",
      "  -2.76577575e-02  1.58143084e-01 -3.31005101e-02 -2.05756169e-02\n",
      "  -1.24604928e-01 -1.91283101e-01 -1.84742684e-01  9.29570925e-02\n",
      "   2.27509498e-02  2.40137010e-01  9.30469004e-02 -5.09863353e-04\n",
      "  -3.35993000e-01  1.75128165e-01 -3.96167559e-01 -2.88183340e-01]\n",
      " [ 1.65446465e-01  3.62916640e-01  3.85302817e-01  1.46290988e-01\n",
      "   1.84173325e-01  5.65335122e-02  3.40438315e-01  1.87801120e-01\n",
      "   3.67934545e-02 -8.51426494e-02 -1.53783221e-01 -2.08808030e-01\n",
      "  -5.80232101e-02 -1.37964582e-01 -1.06301837e-01 -7.23629010e-02\n",
      "   1.40069081e-02  3.95307163e-01 -6.70330615e-02  1.70390986e-01\n",
      "  -2.23570894e-01  2.47879859e-01  2.22456048e-01  1.30691577e-01]\n",
      " [-1.06991548e-01 -9.38005769e-02  3.50014012e-02  1.96404182e-02\n",
      "   1.41097523e-01  1.01339985e-01 -1.64134079e-02 -4.26551389e-02\n",
      "  -1.29554859e-01 -1.95158512e-01  2.14251980e-01  4.28588758e-01\n",
      "  -2.05623536e-02  3.27074554e-01 -5.23975572e-01  4.37463878e-01\n",
      "  -2.28149645e-02  2.20240737e-01 -5.98059360e-02 -2.96915857e-02\n",
      "  -9.68271978e-02 -5.46978634e-04  1.23761531e-01  9.95465970e-02]\n",
      " [ 6.82235858e-02  2.49111311e-01  2.02751903e-01 -4.91302567e-02\n",
      "   1.23885213e-01 -1.34465527e-02 -1.76916998e-01 -3.02563470e-01\n",
      "   3.23651685e-01  3.04816446e-01  2.45516849e-01 -2.84747095e-02\n",
      "   4.33342749e-01  1.59546585e-01  9.05630636e-02  1.30740380e-01\n",
      "  -1.01513849e-01  1.47616103e-01 -1.80303230e-01  3.10094856e-02\n",
      "  -1.63772804e-01  6.09009321e-02 -2.15166820e-01 -3.34233655e-01]\n",
      " [-2.72363290e-01 -3.63874498e-01 -6.25826614e-02  2.13004618e-01\n",
      "   5.10585927e-02  3.06149210e-02  2.24346320e-01  1.54234002e-01\n",
      "  -1.02739268e-01 -2.14457400e-01  2.66133962e-01 -1.11057395e-01\n",
      "   5.06904161e-01  9.65031368e-02  3.75093389e-01  5.20035986e-02\n",
      "   4.32345903e-02  3.41602694e-02  8.49427321e-02  1.59160389e-01\n",
      "  -5.64138672e-02  2.47320772e-01  1.09913471e-01  7.12418138e-02]\n",
      " [-1.18278906e-01  3.30802461e-01 -3.21952960e-01  1.77233639e-01\n",
      "   8.09291283e-02  1.68471464e-01 -4.85232478e-02  5.46432244e-02\n",
      "  -4.35842510e-02  1.70019053e-02 -6.25135086e-02 -3.62484849e-01\n",
      "   2.40250770e-01 -4.98973086e-02 -2.32672119e-01  2.31844408e-01\n",
      "   1.19486217e-01  1.72317378e-01  1.36723213e-01  5.73188069e-02\n",
      "   5.52265089e-01 -1.46530468e-01 -5.43086998e-02 -1.68932880e-02]\n",
      " [-1.31480365e-01 -4.19528245e-02 -1.02359498e-01 -3.83809640e-01\n",
      "   8.06982998e-02  2.67718185e-02  1.41743681e-01  4.98033941e-02\n",
      "   1.74818265e-01  1.73681364e-01 -2.65956715e-02  2.39828728e-01\n",
      "  -2.07974004e-01  1.70212850e-01  7.62030619e-02 -1.08578046e-01\n",
      "   4.32594531e-01  2.48554690e-01  2.63073349e-01  3.64081810e-01\n",
      "   1.70039176e-01  2.50005975e-01 -1.16086825e-01 -1.70347908e-01]]\n",
      "*****************************************************************\n",
      "PCs\n",
      "*****************************************************************\n",
      "[[-9.14135313e-01  1.88466435e+00  1.08962045e+00 ... -3.06590560e-01\n",
      "  -1.22360030e-01  3.95535166e-01]\n",
      " [ 3.53091860e+00 -1.52257632e+00  6.77451033e-01 ...  6.43466142e-01\n",
      "   1.28638763e+00  1.00505787e-01]\n",
      " [-1.49226831e+00  6.13585364e-01 -2.16810350e+00 ... -1.67231783e-03\n",
      "   1.39088660e+00 -6.59809649e-01]\n",
      " ...\n",
      " [ 4.58503827e-01  6.51052338e-01  1.72981571e+00 ...  3.70152627e-01\n",
      "   5.28168365e-01  3.46226482e-01]\n",
      " [-7.11542160e-01 -1.84848241e+00 -1.77460432e+00 ...  1.35468147e+00\n",
      "   9.03966928e-01  5.32809600e-02]\n",
      " [ 2.15948482e+00 -2.23038636e+00  8.46360253e-01 ...  7.49759521e-01\n",
      "   7.17606512e-01 -4.98831799e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.set_params(n_components = 12) # only obtain 12 PCs = p\n",
    "pca.fit(data_sent_s)\n",
    "\n",
    "print 'Aggregated Explained Variance', 100*round(sum(pca.explained_variance_ratio_),2)\n",
    "print '*'*65\n",
    "print 'Explained Variance per  PC:'\n",
    "print '*'*65\n",
    "print pca.explained_variance_ratio_\n",
    "print '*'*65\n",
    "print 'PCA Eigenvectors'\n",
    "print '*'*65\n",
    "print pca.components_\n",
    "print '*'*65\n",
    "print 'PCs'\n",
    "print '*'*65\n",
    "print pca.transform(data_sent_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is: 0.1486\n",
      "The test error is: 0.2105\n",
      "Training Multi Class Log_loss: 0.39828269745520434\n",
      "Test Multi Class Log_loss: 0.541899051837033\n"
     ]
    }
   ],
   "source": [
    "import sklearn.cross_validation as cv\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "logit = lm.LogisticRegression()\n",
    "\n",
    "pred = data_sent_s\n",
    "target = data['Target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = cv.train_test_split(pred, target, test_size=0.20, random_state=0)\n",
    "\n",
    "# PCA Training\n",
    "pca.set_params(n_components = 12) \n",
    "pca.fit(x_train)\n",
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "\n",
    "# Logit \n",
    "logit.fit(x_train, y_train)\n",
    "print \"The training error is: %.4f\" %(1-logit.score(x_train, y_train))\n",
    "print \"The test error is: %.4f\" %(1-logit.score(x_test, y_test))\n",
    "y_train_p = logit.predict_proba(x_train)\n",
    "y_test_p = logit.predict_proba(x_test)\n",
    "print 'Training Multi Class Log_loss:', metrics.log_loss(y_train,y_train_p)\n",
    "print 'Test Multi Class Log_loss:', metrics.log_loss(y_test,y_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Error rates per fold: [0.13333333 0.2        0.2        0.26666667 0.21428571]\n",
      "CV Average Error 0.20285714285714285\n",
      "CV Error Std. Dev 0.04254915791178798\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation\n",
    "import sklearn.cross_validation as cv\n",
    "stratify_divide = cv.StratifiedKFold(y_train, 5, random_state=0)\n",
    "scores = cv.cross_val_score(logit, x_train, y_train, cv=stratify_divide)\n",
    "print 'CV Error rates per fold:', 1- scores\n",
    "print 'CV Average Error', 1-np.mean(scores)\n",
    "print 'CV Error Std. Dev', np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Input\n",
    "y_logitsent_train_p = logit.predict(x_train)\n",
    "y_logitsent_train_prob = logit.predict_proba(x_train)\n",
    "\n",
    "y_logitsent_test_p = logit.predict(x_test)\n",
    "y_logitsent_test_prob = logit.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Assemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model 1: Soft  = Majority Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_1 = pd.DataFrame({'0_logit':y_logit_train_prob[:,0], '1_logit':y_logit_train_prob[:,1],\n",
    "                        '0_rf': y_rf_train_prob[:,0], '1_rf': y_rf_train_prob[:,1], \n",
    "                        '0_xgb':y_xgb_train_prob[:,0], '1_xgb':y_xgb_train_prob[:,1],\n",
    "                        '0_logitsent':y_logitsent_train_prob[:,0], '1_logitsent':y_logitsent_train_prob[:,1]\n",
    "                       })\n",
    "df_pred_1['0_avg']= np.average(df_pred_1[['0_logit','0_rf','0_xgb','0_logitsent']],axis=1)\n",
    "df_pred_1['1_avg']= np.average(df_pred_1[['1_logit','1_rf','1_xgb','1_logitsent']],axis=1)\n",
    "df_pred_1['Pred']= [0 if list(df_pred_1['0_avg'])[i] > list(df_pred_1['1_avg'])[i] else 1 for i in range(0,len(df_pred_1),1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ensemble Train Score 0.98649\n",
      "Ensemble Train Error 0.01351\n",
      "Ensemble Train Log-Loss 0.20116\n"
     ]
    }
   ],
   "source": [
    "# Train Ensemble\n",
    "y_target = pd.DataFrame(pd.Series(y_train).values)\n",
    "\n",
    "score = float(sum(y_target[0]==df_pred_1['Pred']))/len(y_target)\n",
    "error = 1- score\n",
    "\n",
    "print 'Ensemble Train Score', round(score,5)\n",
    "print 'Ensemble Train Error', round(1 - score,5)\n",
    "print 'Ensemble Train Log-Loss', round(metrics.log_loss(y_target,np.array(df_pred_1[['0_avg','1_avg']])),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Test Score 0.84211\n",
      "Ensemble Test Error 0.15789\n",
      "Ensemble Test Log-Loss 0.36678\n"
     ]
    }
   ],
   "source": [
    "# Test Ensemble\n",
    "y_target = pd.DataFrame(pd.Series(y_test).values)\n",
    "\n",
    "\n",
    "y_logit_prob = y_logit_test_prob\n",
    "y_rf_prob = y_rf_test_prob\n",
    "y_xgb_prob = y_xgb_test_prob\n",
    "y_logitsent_prob = y_logitsent_test_prob\n",
    "\n",
    "\n",
    "df_pred = pd.DataFrame({'0_logit':y_logit_prob[:,0], '1_logit':y_logit_prob[:,1],\n",
    "                        '0_rf': y_rf_prob[:,0], '1_rf': y_rf_prob[:,1], \n",
    "                        '0_xgb':y_xgb_prob[:,0], '1_xgb':y_xgb_prob[:,1],\n",
    "                        '0_logitsent':y_logitsent_prob[:,0], '1_logitsent':y_logitsent_prob[:,1],\n",
    "                       })\n",
    "df_pred['0_avg']= np.average(df_pred[['0_logit','0_rf','0_xgb','0_logitsent']],axis=1)\n",
    "df_pred['1_avg']= np.average(df_pred[['1_logit','1_rf','1_xgb','1_logitsent']],axis=1)\n",
    "df_pred['Pred']= [0 if list(df_pred['0_avg'])[i] > list(df_pred['1_avg'])[i] else 1 for i in range(0,len(df_pred),1)]\n",
    "\n",
    "score = float(sum(y_target[0]==df_pred['Pred']))/len(y_target)\n",
    "error = 1- score\n",
    "\n",
    "\n",
    "print 'Ensemble Test Score', round(score,5)\n",
    "print 'Ensemble Test Error', round(1 - score,5)\n",
    "print 'Ensemble Test Log-Loss', round(metrics.log_loss(y_target,np.array(df_pred[['0_avg','1_avg']])),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model 2: Soft  = Majority Rule - Only PCA Logit Total and RF Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Train Score 0.95946\n",
      "Ensemble Train Error 0.04054\n",
      "Ensemble Train Log-Loss 0.22908\n"
     ]
    }
   ],
   "source": [
    "# Train Ensemble\n",
    "y_target = pd.DataFrame(pd.Series(y_train).values)\n",
    "\n",
    "\n",
    "y_logit_prob = y_logit_train_prob\n",
    "y_rf_prob = y_rf_train_prob\n",
    "\n",
    "\n",
    "df_pred = pd.DataFrame({'0_logit':y_logit_prob[:,0], '1_logit':y_logit_prob[:,1],\n",
    "                        '0_rf': y_rf_prob[:,0], '1_rf': y_rf_prob[:,1]                    \n",
    "                       })\n",
    "df_pred['0_avg']= np.average(df_pred[['0_logit','0_rf']],axis=1)\n",
    "df_pred['1_avg']= np.average(df_pred[['1_logit','1_rf',]],axis=1)\n",
    "df_pred['Pred']= [0 if list(df_pred['0_avg'])[i] > list(df_pred['1_avg'])[i] else 1 for i in range(0,len(df_pred),1)]\n",
    "\n",
    "score = float(sum(y_target[0]==df_pred['Pred']))/len(y_target)\n",
    "error = 1- score\n",
    "\n",
    "print 'Ensemble Train Score', round(score,5)\n",
    "print 'Ensemble Train Error', round(1 - score,5)\n",
    "print 'Ensemble Train Log-Loss', round(metrics.log_loss(y_target,np.array(df_pred[['0_avg','1_avg']])),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Test Score 0.78947\n",
      "Ensemble Test Error 0.21053\n",
      "Ensemble Test Log-Loss 0.37747\n"
     ]
    }
   ],
   "source": [
    "# Test Ensemble\n",
    "y_target = pd.DataFrame(pd.Series(y_test).values)\n",
    "\n",
    "\n",
    "y_logit_prob = y_logit_test_prob\n",
    "y_rf_prob = y_rf_test_prob\n",
    "\n",
    "\n",
    "df_pred = pd.DataFrame({'0_logit':y_logit_prob[:,0], '1_logit':y_logit_prob[:,1],\n",
    "                        '0_rf': y_rf_prob[:,0], '1_rf': y_rf_prob[:,1]\n",
    "                       })\n",
    "\n",
    "df_pred['0_avg']= np.average(df_pred[['0_logit','0_rf']],axis=1)\n",
    "df_pred['1_avg']= np.average(df_pred[['1_logit','1_rf']],axis=1)\n",
    "df_pred['Pred']= [0 if list(df_pred['0_avg'])[i] > list(df_pred['1_avg'])[i] else 1 for i in range(0,len(df_pred),1)]\n",
    "\n",
    "score = float(sum(y_target[0]==df_pred['Pred']))/len(y_target)\n",
    "error = 1- score\n",
    "\n",
    "\n",
    "print 'Ensemble Test Score', round(score,5)\n",
    "print 'Ensemble Test Error', round(1 - score,5)\n",
    "print 'Ensemble Test Log-Loss', round(metrics.log_loss(y_target,np.array(df_pred[['0_avg','1_avg']])),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
